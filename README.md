# ğŸ“„ Enterprise Document Intelligence System

**LLM-Powered Knowledge Extraction & Retrieval (RAG)**

ğŸ”— **Live API (Swagger UI):**  
ğŸ‘‰ https://enterprise-docs-ai-production.up.railway.app/docs

---

## ğŸš€ Overview

The **Enterprise Document Intelligence System** is a cloud-native, multi-tenant platform that enables organizations to ingest documents, extract knowledge, and perform **secure, explainable, LLM-powered question answering** over their internal data.

This system is designed for **real enterprise use cases** such as:

- Internal knowledge search
- Policy & compliance analysis
- Research intelligence
- Document-heavy decision support

---

## âœ¨ Key Features

### ğŸ” Authentication & RBAC

- JWT-based authentication
- Role-based access control (Admin / User)
- Strict per-user document isolation (multi-tenancy)

### ğŸ“¥ Intelligent Document Ingestion

- PDF upload with automatic parsing
- Adaptive chunking strategy based on:
  - Document structure
  - End-use (Q&A focused retrieval)
- Rich metadata captured for traceability

### ğŸ” Semantic Search + RAG

- High-performance vector search using **Pinecone**
- Retrieval-Augmented Generation (RAG)
- **Groq-powered LLM inference** for low-latency responses
- Answers strictly grounded in retrieved document context

### ğŸ“Œ Source Citations

- Every response includes:
  - Source document name
  - Chunk index
  - Relevance score
- Enables explainability and enterprise trust

### ğŸ“Š Usage Analytics

- Per-user query tracking
- Usage logging for monitoring and future billing
- Designed for scalability and observability

### â˜ï¸ Cloud-Native Architecture

- Fully Dockerized backend
- Deployed on **Railway**
- External managed services for reliability and scale

---

## ğŸ§  System Architecture

```
Client (Swagger / UI)
        â†“
FastAPI Backend (Railway)
    â”œâ”€â”€ Auth & RBAC
    â”œâ”€â”€ Document Upload & Parsing
    â”œâ”€â”€ Adaptive Chunking Engine
    â”œâ”€â”€ Vector Store (Pinecone)
    â”œâ”€â”€ RAG Pipeline
    â””â”€â”€ Usage Analytics
        â†“
External Services
    â”œâ”€â”€ Supabase Postgres (Metadata + Analytics)
    â”œâ”€â”€ Pinecone (Vector Search)
    â””â”€â”€ Groq (LLM Inference)
```

---

## ğŸ—‚ Backend Structure

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ auth.py              # Authentication endpoints
â”‚   â”‚   â”œâ”€â”€ upload.py            # Document ingestion
â”‚   â”‚   â”œâ”€â”€ query.py             # RAG query endpoint
â”‚   â”‚   â”œâ”€â”€ admin.py             # Admin operations
â”‚   â”‚   â””â”€â”€ dependencies.py      # Security dependencies
â”‚   â”‚
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ config.py            # Centralized configuration
â”‚   â”‚   â”œâ”€â”€ database.py          # SQLAlchemy setup
â”‚   â”‚   â””â”€â”€ security.py          # JWT utilities
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ user.py              # User schema
â”‚   â”‚   â”œâ”€â”€ document.py          # Document metadata
â”‚   â”‚   â””â”€â”€ usage.py             # Query analytics
â”‚   â”‚
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ auth.py              # Auth logic
â”‚   â”‚   â”œâ”€â”€ chunking.py          # Adaptive chunking
â”‚   â”‚   â”œâ”€â”€ vector_store.py      # Pinecone upsert logic
â”‚   â”‚   â”œâ”€â”€ retriever.py         # Semantic retrieval
â”‚   â”‚   â”œâ”€â”€ rag.py               # RAG orchestration
â”‚   â”‚   â”œâ”€â”€ llm.py               # Groq integration
â”‚   â”‚   â””â”€â”€ analytics.py         # Usage tracking
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ file_loader.py       # PDF text extraction
â”‚   â”‚
â”‚   â””â”€â”€ main.py                  # Application entry point
â”‚
â”œâ”€â”€ Dockerfile
â””â”€â”€ requirements.txt
```

---

## ğŸ” RAG Execution Flow

1. User uploads a document
2. Document is parsed and chunked intelligently
3. Chunks are embedded and stored in Pinecone
4. User submits a query
5. Relevant chunks are retrieved semantically
6. Retrieved context is passed to the LLM
7. Final answer is generated with citations

---

## ğŸ“Œ Example API Response

```json
{
  "answer": "The internship duration mentioned in the document is 6 months.",
  "sources": [
    {
      "filename": "Internship_Description.pdf",
      "chunk_index": 3,
      "score": 0.91
    }
  ]
}
```

---

## ğŸ›¡ï¸ Security & Isolation

- Namespace-based vector isolation per user
- JWT validation on every request
- No cross-user data leakage
- LLM responses restricted to retrieved context only

---

## ğŸ“ˆ Designed for Scale

- Stateless backend
- External vector and database services
- Ready for hybrid dense + sparse search
- Easy extension to streaming and reranking